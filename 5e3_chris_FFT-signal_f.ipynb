{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool,CatBoostRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "pd.set_option(\"display.precision\", 8)\n",
    "\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pywt \n",
    "from statsmodels.robust import mad\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, deconvolve, find_peaks, peak_widths, peak_prominences\n",
    "\n",
    "from numpy.fft import *\n",
    "\n",
    "import time\n",
    "import math\n",
    "from numba import jit\n",
    "from math import log, floor\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "import itertools\n",
    "import warnings\n",
    "import time\n",
    "import pywt\n",
    "import os\n",
    "import gc\n",
    "\n",
    "train = pd.read_csv('/Users/siero5335/channel/train.csv')\n",
    "test = pd.read_csv('/Users/siero5335/channel/test.csv')\n",
    "train2 = pd.read_csv('/Users/siero5335/channel/train2.csv')\n",
    "test2 = pd.read_csv('/Users/siero5335/channel/test2.csv')\n",
    "\n",
    "\n",
    "sample_submission = pd.read_csv('/Users/siero5335/channel/sample_submission.csv')\n",
    "\n",
    "train2 = train2.iloc[:,1]\n",
    "test2 = test2.iloc[:,1]\n",
    "\n",
    "train = pd.concat([train, train2], axis=1)\n",
    "test = pd.concat([test, test2], axis=1)\n",
    "\n",
    "train_f = pd.read_csv('/Users/siero5335/channel/test_rolling_signal_chris.csv')\n",
    "test_f = pd.read_csv('/Users/siero5335/channel/test_rolling_signal_chris.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f = train_f.drop(train_f.columns[0], axis= 1)\n",
    "test_f = test_f.drop(test_f.columns[0], axis= 1)\n",
    "\n",
    "train_f = train_f.drop(train_f.columns[0], axis= 1)\n",
    "test_f = test_f.drop(test_f.columns[0], axis= 1)\n",
    "\n",
    "train_f = train_f.drop(['signal_chris'], axis= 1)\n",
    "test_f = test_f.drop(['signal_chris'], axis= 1)\n",
    "\n",
    "train = pd.concat([train, train_f], axis = 1)\n",
    "test = pd.concat([test, test_f], axis = 1)\n",
    "\n",
    "train = train.drop('signal', axis = 1)\n",
    "test = test.drop('signal', axis = 1)\n",
    "\n",
    "train = train.rename(columns={'signal_chris': 'signal'})\n",
    "test = test.rename(columns={'signal_chris': 'signal'})\n",
    "\n",
    "del train2, test2, train_f, test_f\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maddest(d, axis=None):\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "def high_pass_filter(x, low_cutoff=1000, sample_rate=10000):\n",
    "\n",
    "    nyquist = 0.5 * sample_rate\n",
    "    norm_low_cutoff = low_cutoff / nyquist\n",
    "    print(norm_low_cutoff)\n",
    "    sos = butter(10, Wn=[norm_low_cutoff], btype='highpass', output='sos')\n",
    "    filtered_sig = signal.sosfilt(sos, x)\n",
    "\n",
    "    return filtered_sig\n",
    "\n",
    "def denoise_signal( x, wavelet='db4', level=1):\n",
    "    \n",
    "    coeff = pywt.wavedec( x, wavelet, mode=\"per\" )\n",
    "    sigma = (1/0.6745) * maddest( coeff[-level] )\n",
    "    uthresh = sigma * np.sqrt( 2*np.log( len( x ) ) )\n",
    "    coeff[1:] = ( pywt.threshold( i, value=uthresh, mode='hard' ) for i in coeff[1:] )\n",
    "    return pywt.waverec( coeff, wavelet, mode='per' )\n",
    "\n",
    "train['signal_wave'] = denoise_signal(train['signal'])\n",
    "test['signal_wave'] = denoise_signal(test['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signal(signal, threshold=1e8):\n",
    "    fourier = rfft(signal)\n",
    "    frequencies = rfftfreq(signal.size, d=20e-3/signal.size)\n",
    "    fourier[frequencies > threshold] = 0\n",
    "    return irfft(fourier)\n",
    "\n",
    "train['signal_FFT_1e5'] = filter_signal(train['signal'], threshold=5e3)\n",
    "test['signal_FFT_1e5'] = filter_signal(test['signal'], threshold=5e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _embed(x, order=3, delay=1):\n",
    "    N = len(x)\n",
    "    if order * delay > N:\n",
    "        raise ValueError(\"Error: order * delay should be lower than x.size\")\n",
    "    if delay < 1:\n",
    "        raise ValueError(\"Delay has to be at least 1.\")\n",
    "    if order < 2:\n",
    "        raise ValueError(\"Order has to be at least 2.\")\n",
    "    Y = np.zeros((order, N - (order - 1) * delay))\n",
    "    for i in range(order):\n",
    "        Y[i] = x[i * delay:i * delay + Y.shape[1]]\n",
    "    return Y.T\n",
    "\n",
    "all = ['perm_entropy', 'spectral_entropy', 'svd_entropy', 'app_entropy',\n",
    "       'sample_entropy']\n",
    "\n",
    "\n",
    "def perm_entropy(x, order=3, delay=1, normalize=False):\n",
    "    x = np.array(x)\n",
    "    ran_order = range(order)\n",
    "    hashmult = np.power(order, ran_order)\n",
    "    # Embed x and sort the order of permutations\n",
    "    sorted_idx = _embed(x, order=order, delay=delay).argsort(kind='quicksort')\n",
    "    # Associate unique integer to each permutations\n",
    "    hashval = (np.multiply(sorted_idx, hashmult)).sum(1)\n",
    "    # Return the counts\n",
    "    _, c = np.unique(hashval, return_counts=True)\n",
    "    # Use np.true_divide for Python 2 compatibility\n",
    "    p = np.true_divide(c, c.sum())\n",
    "    pe = -np.multiply(p, np.log2(p)).sum()\n",
    "    if normalize:\n",
    "        pe /= np.log2(factorial(order))\n",
    "    return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log_n(min_n, max_n, factor):\n",
    "    max_i = int(floor(log(1.0 * max_n / min_n) / log(factor)))\n",
    "    ns = [min_n]\n",
    "    for i in range(max_i + 1):\n",
    "        n = int(floor(min_n * (factor ** i)))\n",
    "        if n > ns[-1]:\n",
    "            ns.append(n)\n",
    "    return np.array(ns, dtype=np.int64)\n",
    "\n",
    "def _higuchi_fd(x, kmax):\n",
    "    n_times = x.size\n",
    "    lk = np.empty(kmax)\n",
    "    x_reg = np.empty(kmax)\n",
    "    y_reg = np.empty(kmax)\n",
    "    for k in range(1, kmax + 1):\n",
    "        lm = np.empty((k,))\n",
    "        for m in range(k):\n",
    "            ll = 0\n",
    "            n_max = floor((n_times - m - 1) / k)\n",
    "            n_max = int(n_max)\n",
    "            for j in range(1, n_max):\n",
    "                ll += abs(x[m + j * k] - x[m + (j - 1) * k])\n",
    "            ll /= k\n",
    "            ll *= (n_times - 1) / (k * n_max)\n",
    "            lm[m] = ll\n",
    "        # Mean of lm\n",
    "        m_lm = 0\n",
    "        for m in range(k):\n",
    "            m_lm += lm[m]\n",
    "        m_lm /= k\n",
    "        lk[k - 1] = m_lm\n",
    "        x_reg[k - 1] = log(1. / k)\n",
    "        y_reg[k - 1] = log(m_lm)\n",
    "    higuchi, _ = _linear_regression(x_reg, y_reg)\n",
    "    return higuchi\n",
    "\n",
    "\n",
    "def higuchi_fd(x, kmax=10):\n",
    "    x = np.asarray(x, dtype=np.float64)\n",
    "    kmax = int(kmax)\n",
    "    return _higuchi_fd(x, kmax)\n",
    "\n",
    "def _linear_regression(x, y):\n",
    "    n_times = x.size\n",
    "    sx2 = 0\n",
    "    sx = 0\n",
    "    sy = 0\n",
    "    sxy = 0\n",
    "    for j in range(n_times):\n",
    "        sx2 += x[j] ** 2\n",
    "        sx += x[j]\n",
    "        sxy += x[j] * y[j]\n",
    "        sy += y[j]\n",
    "    den = n_times * sx2 - (sx ** 2)\n",
    "    num = n_times * sxy - sx * sy\n",
    "    slope = num / den\n",
    "    intercept = np.mean(y) - slope * np.mean(x)\n",
    "    return slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def katz_fd(x):\n",
    "    x = np.array(x)\n",
    "    dists = np.abs(np.ediff1d(x))\n",
    "    ll = dists.sum()\n",
    "    ln = np.log10(np.divide(ll, dists.mean()))\n",
    "    aux_d = x - x[0]\n",
    "    d = np.max(np.abs(aux_d[1:]))\n",
    "    return np.divide(ln, np.add(ln, np.log10(np.divide(d, ll))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        if col!='open_channels':\n",
    "            col_type = df[col].dtypes\n",
    "            if col_type in numerics:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)  \n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df : pd.DataFrame,\n",
    "                      df_test : pd.DataFrame,\n",
    "                      subtract_only : Optional[bool]=True,\n",
    "                      idx_cols : List=['time'],\n",
    "                      target_col : List=['open_channels']) -> Tuple[pd.DataFrame , pd.DataFrame]:\n",
    "    \n",
    "    drops = df.columns[df.isna().sum()>25000]\n",
    "    df = df.drop(drops, axis=1)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.fillna(0)\n",
    "    gc.collect()\n",
    "    if subtract_only == False:\n",
    "        corrcoef_cols = [col for col in df.columns.tolist() if col not in (idx_cols+target_col)]\n",
    "        first=dict(); second=dict(); third=dict()\n",
    "        for col in corrcoef_cols:\n",
    "            ss = np.corrcoef(df[col], df['open_channels'])[0, 1]\n",
    "            first[col] = ss\n",
    "            ss = np.corrcoef(df[col]-df['signal'], df['open_channels'])[0, 1]\n",
    "            second[col] = ss\n",
    "            ss = np.corrcoef(df[col]*df['signal'], df['open_channels'])[0, 1]\n",
    "            third[col] = ss\n",
    "        corr_df = pd.DataFrame.from_dict(\n",
    "            {\n",
    "            'Base':first, \n",
    "            'Signal-Subtracted': second,\n",
    "            'Signal-Multiplied': third\n",
    "            }\n",
    "        ).fillna(0).apply(np.abs).sort_values('Base', ascending=False)\n",
    "\n",
    "        base_cols = corr_df.sort_values('Base', ascending=False).head(100).index.tolist()\n",
    "        multiply_cols = corr_df.sort_values('Signal-Multiplied', ascending=False).head(10).index.tolist()\n",
    "        subtract_cols = corr_df.sort_values('Signal-Subtracted', ascending=False).head(25).index.tolist()\n",
    "        display(corr_df.sort_values('Base', ascending=False).tail(50))\n",
    "        all_cols = list(set(base_cols + multiply_cols + subtract_cols + idx_cols + target_col))\n",
    "        all_cols_test = list(set(base_cols + multiply_cols + subtract_cols + idx_cols))   \n",
    "        drops = list(set(multiply_cols + subtract_cols)-set(base_cols))\n",
    "        df = df[all_cols]\n",
    "        df_test = df_test[all_cols_test]\n",
    "    \n",
    "        for col in multiply_cols:\n",
    "            df[col+'_m'] = df[col] * df['signal']\n",
    "            df_test[col+'_m'] = df_test[col] * df_test['signal']        \n",
    "\n",
    "        df = df.drop(drops, axis=1)\n",
    "    else:\n",
    "        not_imp = ['stdbach_slice2_msignal', 'min_FFT_1e5batch_msignal', 'skewbach_slice2_msignal']\n",
    "        subtract_cols = list(set(df.columns.tolist())-set(idx_cols + target_col + not_imp))\n",
    "\n",
    "    df = reduce_mem_usage(df, False)\n",
    "    df_test = reduce_mem_usage(df_test, False)\n",
    "\n",
    "    gc.collect()\n",
    "    return df, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df : pd.DataFrame,\n",
    "                      df_test : pd.DataFrame,\n",
    "                      subtract_only : Optional[bool]=True,\n",
    "                      idx_cols : List=['time'],\n",
    "                      target_col : List=['open_channels']) -> Tuple[pd.DataFrame , pd.DataFrame]:\n",
    "    \n",
    "    drops = df.columns[df.isna().sum()>25000]\n",
    "    df = df.drop(drops, axis=1)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.fillna(0)\n",
    "    gc.collect()\n",
    "    if subtract_only == False:\n",
    "        corrcoef_cols = [col for col in df.columns.tolist() if col not in (idx_cols+target_col)]\n",
    "        first=dict(); second=dict(); third=dict()\n",
    "        for col in corrcoef_cols:\n",
    "            ss = np.corrcoef(df[col], df['open_channels'])[0, 1]\n",
    "            first[col] = ss\n",
    "            ss = np.corrcoef(df[col]-df['signal'], df['open_channels'])[0, 1]\n",
    "            second[col] = ss\n",
    "            ss = np.corrcoef(df[col]*df['signal'], df['open_channels'])[0, 1]\n",
    "            third[col] = ss\n",
    "        corr_df = pd.DataFrame.from_dict(\n",
    "            {\n",
    "            'Base':first, \n",
    "            'Signal-Subtracted': second,\n",
    "            'Signal-Multiplied': third\n",
    "            }\n",
    "        ).fillna(0).apply(np.abs).sort_values('Base', ascending=False)\n",
    "\n",
    "        base_cols = corr_df.sort_values('Base', ascending=False).head(100).index.tolist()\n",
    "        multiply_cols = corr_df.sort_values('Signal-Multiplied', ascending=False).head(10).index.tolist()\n",
    "        subtract_cols = corr_df.sort_values('Signal-Subtracted', ascending=False).head(25).index.tolist()\n",
    "        display(corr_df.sort_values('Base', ascending=False).tail(50))\n",
    "        all_cols = list(set(base_cols + multiply_cols + subtract_cols + idx_cols + target_col))\n",
    "        all_cols_test = list(set(base_cols + multiply_cols + subtract_cols + idx_cols))   \n",
    "        drops = list(set(multiply_cols + subtract_cols)-set(base_cols))\n",
    "        df = df[all_cols]\n",
    "        df_test = df_test[all_cols_test]\n",
    "    \n",
    "        for col in multiply_cols:\n",
    "            df[col+'_m'] = df[col] * df['signal']\n",
    "            df_test[col+'_m'] = df_test[col] * df_test['signal']        \n",
    "\n",
    "        df = df.drop(drops, axis=1)\n",
    "    else:\n",
    "        not_imp = ['stdbach_slice2_msignal', 'min_FFT_1e5batch_msignal', 'skewbach_slice2_msignal']\n",
    "        subtract_cols = list(set(df.columns.tolist())-set(idx_cols + target_col + not_imp))\n",
    "\n",
    "    df = reduce_mem_usage(df, False)\n",
    "    df_test = reduce_mem_usage(df_test, False)\n",
    "\n",
    "    gc.collect()\n",
    "    return df, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siero5335/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/siero5335/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/siero5335/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:59: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/siero5335/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:61: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/siero5335/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/siero5335/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:69: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zscore = lambda x: (x - x.mean()) / x.std()\n",
    "\n",
    "window_sizes = [3, 10, 25, 50, 100, 500, 1000, 5000]\n",
    "\n",
    "for window in window_sizes:\n",
    "    train[\"rolling_mean_\" + str(window)] = train['signal'].rolling(window=window).mean()\n",
    "    train[\"rolling_std_\" + str(window)] = train['signal'].rolling(window=window).std()\n",
    "    train[\"rolling_min_\" + str(window)] = train['signal'].rolling(window=window).min()\n",
    "    train[\"rolling_max_\" + str(window)] = train['signal'].rolling(window=window).max()\n",
    "    \n",
    "for window in window_sizes:\n",
    "    test[\"rolling_mean_\" + str(window)] = test['signal'].rolling(window=window).mean()\n",
    "    test[\"rolling_std_\" + str(window)] = test['signal'].rolling(window=window).std()\n",
    "    test[\"rolling_min_\" + str(window)] = test['signal'].rolling(window=window).min()\n",
    "    test[\"rolling_max_\" + str(window)] = test['signal'].rolling(window=window).max()\n",
    "    \n",
    "def features(df):\n",
    "    df = df.sort_values(by=['time']).reset_index(drop=True)\n",
    "    df.index = ((df.time * 10_000) - 1).values\n",
    "    df['batch'] = df.index // 50_000\n",
    "    df['batch_index'] = df.index  - (df.batch * 50_000)\n",
    "    df['batch_slices'] = df['batch_index']  // 5_000\n",
    "    df['batch_slices2'] = df.apply(lambda r: '_'.join([str(r['batch']).zfill(3), str(r['batch_slices']).zfill(3)]), axis=1)\n",
    "    \n",
    "    for c in ['batch','batch_slices2']:\n",
    "        d = {}\n",
    "                                            \n",
    "        d['mean'+c] = df.groupby([c])['signal'].mean()\n",
    "        d['median'+c] = df.groupby([c])['signal'].median()\n",
    "        d['max'+c] = df.groupby([c])['signal'].max()\n",
    "        d['min'+c] = df.groupby([c])['signal'].min()\n",
    "        d['std'+c] = df.groupby([c])['signal'].std()             \n",
    "        \n",
    "        d['signal_batch'+c] = df.groupby([c])['signal'].transform(zscore)\n",
    "        d['perm'+c] = df.groupby([c])['signal'].apply(lambda x:perm_entropy(x))\n",
    "        d['higuchi'+c] = df.groupby([c])['signal'].apply(lambda x:higuchi_fd(x))\n",
    "        d['katz'+c] = df.groupby([c])['signal'].apply(lambda x:katz_fd(x))\n",
    "                \n",
    "        d['mean_abs_chg'+c] = df.groupby([c])['signal'].apply(lambda x: np.mean(np.abs(np.diff(x))))\n",
    "        d['abs_max'+c] = df.groupby([c])['signal'].apply(lambda x: np.max(np.abs(x)))\n",
    "        d['abs_min'+c] = df.groupby([c])['signal'].apply(lambda x: np.min(np.abs(x)))\n",
    "        for v in d:\n",
    "            df[v] = df[c].map(d[v].to_dict())\n",
    "        df['range'+c] = df['max'+c] - df['min'+c]\n",
    "        df['maxtomin'+c] = df['max'+c] / df['min'+c]\n",
    "        df['abs_avg'+c] = (df['abs_min'+c] + df['abs_max'+c]) / 2\n",
    "    \n",
    "    #add shifts\n",
    "    df['signal_shift_+1'] = [0,] + list(df['signal'].values[:-1])\n",
    "    df['signal_shift_-1'] = list(df['signal'].values[1:]) + [0]\n",
    "    for i in df[df['batch_index']==0].index:\n",
    "        df['signal_shift_+1'][i] = np.nan\n",
    "    for i in df[df['batch_index']==49999].index:\n",
    "        df['signal_shift_-1'][i] = np.nan\n",
    "        \n",
    "    df['signal_shift_wave_+1'] = [0,] + list(df['signal_wave'].values[:-1])\n",
    "    df['signal_shift_wave_-1'] = list(df['signal_wave'].values[1:]) + [0]\n",
    "    for i in df[df['batch_index']==0].index:\n",
    "        df['signal_shift_wave_+1'][i] = np.nan\n",
    "    for i in df[df['batch_index']==49999].index:\n",
    "        df['signal_shift_wave_-1'][i] = np.nan\n",
    "        \n",
    "        \n",
    "    df['signal_shift_+1_FFT'] = [0,] + list(df['signal_FFT_1e5'].values[:-1])\n",
    "    df['signal_shift_-1_FFT'] = list(df['signal_FFT_1e5'].values[1:]) + [0]\n",
    "    for i in df[df['batch_index']==0].index:\n",
    "        df['signal_shift_+1_FFT'][i] = np.nan\n",
    "    for i in df[df['batch_index']==49999].index:\n",
    "        df['signal_shift_-1_FFT'][i] = np.nan\n",
    "        \n",
    "    for c in [c1 for c1 in df.columns if c1 not in ['time', 'signal', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2', 'signal_wave']]:\n",
    "        df[c+'_msignal'] = df[c] - df['signal']\n",
    "        \n",
    "    return df\n",
    "\n",
    "train = features(train)\n",
    "test = features(test)\n",
    "\n",
    "train['signal_shift+2'] = train.groupby(['batch']).shift(2)['signal']\n",
    "test['signal_shift+2'] = test.groupby(['batch']).shift(2)['signal']\n",
    "train['signal_shift-2'] = train.groupby(['batch']).shift(-2)['signal']\n",
    "test['signal_shift-2'] = test.groupby(['batch']).shift(-2)['signal']\n",
    "\n",
    "\n",
    "train['signal_shift+2_wave_-1'] = train.groupby(['batch']).shift(2)['signal_wave']\n",
    "test['signal_shift+2_wave_-1'] = test.groupby(['batch']).shift(2)['signal_wave']\n",
    "train['signal_shift-2_wave_-1'] = train.groupby(['batch']).shift(-2)['signal_wave']\n",
    "test['signal_shift-2_wave_-1'] = test.groupby(['batch']).shift(-2)['signal_wave']\n",
    "\n",
    "\n",
    "train['signal_shift+2_FFT'] = train.groupby(['batch']).shift(2)['signal_FFT_1e5']\n",
    "test['signal_shift+2_FFT'] = test.groupby(['batch']).shift(2)['signal_FFT_1e5']\n",
    "train['signal_shift-2_FFT'] = train.groupby(['batch']).shift(-2)['signal_FFT_1e5']\n",
    "test['signal_shift-2_FFT'] = test.groupby(['batch']).shift(-2)['signal_FFT_1e5']\n",
    "\n",
    "train.fillna(0, inplace=True)\n",
    "test.fillna(0, inplace=True)\n",
    "\n",
    "train_y = train['open_channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open_channels</th>\n",
       "      <th>signal</th>\n",
       "      <th>rolling_height_mean_chris_100</th>\n",
       "      <th>rolling_width_mean_chris_100</th>\n",
       "      <th>rolling_height_mean_chris_500</th>\n",
       "      <th>rolling_width_mean_chris_500</th>\n",
       "      <th>rolling_height_mean_chris_1000</th>\n",
       "      <th>rolling_width_mean_chris_1000</th>\n",
       "      <th>rolling_height_mean_chris_2500</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_shift_wave_+1_msignal</th>\n",
       "      <th>signal_shift_wave_-1_msignal</th>\n",
       "      <th>signal_shift_+1_FFT_msignal</th>\n",
       "      <th>signal_shift_-1_FFT_msignal</th>\n",
       "      <th>signal_shift+2</th>\n",
       "      <th>signal_shift-2</th>\n",
       "      <th>signal_shift+2_wave_-1</th>\n",
       "      <th>signal_shift-2_wave_-1</th>\n",
       "      <th>signal_shift+2_FFT</th>\n",
       "      <th>signal_shift-2_FFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.7600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-0.78580580</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>3.12709392</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-2.4074</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-0.95419929</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.36685675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.8557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35638109</td>\n",
       "      <td>1.90150071</td>\n",
       "      <td>3.22303109</td>\n",
       "      <td>3.22255675</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-3.1404</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-1.32866244</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.36661957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.4074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.13840580</td>\n",
       "      <td>1.07873756</td>\n",
       "      <td>2.77449392</td>\n",
       "      <td>2.77401957</td>\n",
       "      <td>-2.7600</td>\n",
       "      <td>-3.1525</td>\n",
       "      <td>-2.49931891</td>\n",
       "      <td>-3.60514371</td>\n",
       "      <td>0.36733109</td>\n",
       "      <td>0.36638240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.1404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.18620071</td>\n",
       "      <td>-0.46474371</td>\n",
       "      <td>3.50725675</td>\n",
       "      <td>3.50678240</td>\n",
       "      <td>-2.8557</td>\n",
       "      <td>-2.6418</td>\n",
       "      <td>-3.54580580</td>\n",
       "      <td>-4.06727689</td>\n",
       "      <td>0.36709392</td>\n",
       "      <td>0.36614523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.1525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.82383756</td>\n",
       "      <td>-0.91477689</td>\n",
       "      <td>3.51911957</td>\n",
       "      <td>3.51864523</td>\n",
       "      <td>-2.4074</td>\n",
       "      <td>-2.6993</td>\n",
       "      <td>-0.95419929</td>\n",
       "      <td>-3.59025109</td>\n",
       "      <td>0.36685675</td>\n",
       "      <td>0.36590806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  open_channels  signal  rolling_height_mean_chris_100  \\\n",
       "0.0  0.0001              0 -2.7600                            0.0   \n",
       "1.0  0.0002              0 -2.8557                            0.0   \n",
       "2.0  0.0003              0 -2.4074                            0.0   \n",
       "3.0  0.0004              0 -3.1404                            0.0   \n",
       "4.0  0.0005              0 -3.1525                            0.0   \n",
       "\n",
       "     rolling_width_mean_chris_100  rolling_height_mean_chris_500  \\\n",
       "0.0                           0.0                            0.0   \n",
       "1.0                           0.0                            0.0   \n",
       "2.0                           0.0                            0.0   \n",
       "3.0                           0.0                            0.0   \n",
       "4.0                           0.0                            0.0   \n",
       "\n",
       "     rolling_width_mean_chris_500  rolling_height_mean_chris_1000  \\\n",
       "0.0                           0.0                             0.0   \n",
       "1.0                           0.0                             0.0   \n",
       "2.0                           0.0                             0.0   \n",
       "3.0                           0.0                             0.0   \n",
       "4.0                           0.0                             0.0   \n",
       "\n",
       "     rolling_width_mean_chris_1000  rolling_height_mean_chris_2500  ...  \\\n",
       "0.0                            0.0                             0.0  ...   \n",
       "1.0                            0.0                             0.0  ...   \n",
       "2.0                            0.0                             0.0  ...   \n",
       "3.0                            0.0                             0.0  ...   \n",
       "4.0                            0.0                             0.0  ...   \n",
       "\n",
       "     signal_shift_wave_+1_msignal  signal_shift_wave_-1_msignal  \\\n",
       "0.0                    0.00000000                   -0.78580580   \n",
       "1.0                    0.35638109                    1.90150071   \n",
       "2.0                   -1.13840580                    1.07873756   \n",
       "3.0                    2.18620071                   -0.46474371   \n",
       "4.0                    1.82383756                   -0.91477689   \n",
       "\n",
       "     signal_shift_+1_FFT_msignal  signal_shift_-1_FFT_msignal  signal_shift+2  \\\n",
       "0.0                   0.00000000                   3.12709392          0.0000   \n",
       "1.0                   3.22303109                   3.22255675          0.0000   \n",
       "2.0                   2.77449392                   2.77401957         -2.7600   \n",
       "3.0                   3.50725675                   3.50678240         -2.8557   \n",
       "4.0                   3.51911957                   3.51864523         -2.4074   \n",
       "\n",
       "     signal_shift-2  signal_shift+2_wave_-1  signal_shift-2_wave_-1  \\\n",
       "0.0         -2.4074              0.00000000             -0.95419929   \n",
       "1.0         -3.1404              0.00000000             -1.32866244   \n",
       "2.0         -3.1525             -2.49931891             -3.60514371   \n",
       "3.0         -2.6418             -3.54580580             -4.06727689   \n",
       "4.0         -2.6993             -0.95419929             -3.59025109   \n",
       "\n",
       "     signal_shift+2_FFT  signal_shift-2_FFT  \n",
       "0.0          0.00000000          0.36685675  \n",
       "1.0          0.00000000          0.36661957  \n",
       "2.0          0.36733109          0.36638240  \n",
       "3.0          0.36709392          0.36614523  \n",
       "4.0          0.36685675          0.36590806  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>signal</th>\n",
       "      <th>rolling_height_mean_chris_100</th>\n",
       "      <th>rolling_width_mean_chris_100</th>\n",
       "      <th>rolling_height_mean_chris_500</th>\n",
       "      <th>rolling_width_mean_chris_500</th>\n",
       "      <th>rolling_height_mean_chris_1000</th>\n",
       "      <th>rolling_width_mean_chris_1000</th>\n",
       "      <th>rolling_height_mean_chris_2500</th>\n",
       "      <th>rolling_width_mean_chris_2500</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_shift_wave_+1_msignal</th>\n",
       "      <th>signal_shift_wave_-1_msignal</th>\n",
       "      <th>signal_shift_+1_FFT_msignal</th>\n",
       "      <th>signal_shift_-1_FFT_msignal</th>\n",
       "      <th>signal_shift+2</th>\n",
       "      <th>signal_shift-2</th>\n",
       "      <th>signal_shift+2_wave_-1</th>\n",
       "      <th>signal_shift-2_wave_-1</th>\n",
       "      <th>signal_shift+2_FFT</th>\n",
       "      <th>signal_shift-2_FFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000000.0</td>\n",
       "      <td>500.0001</td>\n",
       "      <td>-2.64983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-0.05779149</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-0.03925862</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-2.86009</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-2.70760720</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-2.68909018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000001.0</td>\n",
       "      <td>500.0002</td>\n",
       "      <td>-2.84946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14182432</td>\n",
       "      <td>0.14185280</td>\n",
       "      <td>0.16037293</td>\n",
       "      <td>0.16036982</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-2.43512</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-2.70759352</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-2.68909172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000002.0</td>\n",
       "      <td>500.0003</td>\n",
       "      <td>-2.86009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15246851</td>\n",
       "      <td>0.15249648</td>\n",
       "      <td>0.17100138</td>\n",
       "      <td>0.17099828</td>\n",
       "      <td>-2.64983</td>\n",
       "      <td>-2.61565</td>\n",
       "      <td>-2.70763568</td>\n",
       "      <td>-2.70758051</td>\n",
       "      <td>-2.68908707</td>\n",
       "      <td>-2.68909327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000003.0</td>\n",
       "      <td>500.0004</td>\n",
       "      <td>-2.43512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.27248720</td>\n",
       "      <td>-0.27246051</td>\n",
       "      <td>-0.25397018</td>\n",
       "      <td>-0.25397327</td>\n",
       "      <td>-2.84946</td>\n",
       "      <td>-2.56608</td>\n",
       "      <td>-2.70762149</td>\n",
       "      <td>-2.70756785</td>\n",
       "      <td>-2.68908862</td>\n",
       "      <td>-2.68909481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000004.0</td>\n",
       "      <td>500.0005</td>\n",
       "      <td>-2.61565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.09194352</td>\n",
       "      <td>-0.09191785</td>\n",
       "      <td>-0.07344172</td>\n",
       "      <td>-0.07344481</td>\n",
       "      <td>-2.86009</td>\n",
       "      <td>-2.73801</td>\n",
       "      <td>-2.70760720</td>\n",
       "      <td>-2.70755576</td>\n",
       "      <td>-2.68909018</td>\n",
       "      <td>-2.68909635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time   signal  rolling_height_mean_chris_100  \\\n",
       "5000000.0  500.0001 -2.64983                            0.0   \n",
       "5000001.0  500.0002 -2.84946                            0.0   \n",
       "5000002.0  500.0003 -2.86009                            0.0   \n",
       "5000003.0  500.0004 -2.43512                            0.0   \n",
       "5000004.0  500.0005 -2.61565                            0.0   \n",
       "\n",
       "           rolling_width_mean_chris_100  rolling_height_mean_chris_500  \\\n",
       "5000000.0                           0.0                            0.0   \n",
       "5000001.0                           0.0                            0.0   \n",
       "5000002.0                           0.0                            0.0   \n",
       "5000003.0                           0.0                            0.0   \n",
       "5000004.0                           0.0                            0.0   \n",
       "\n",
       "           rolling_width_mean_chris_500  rolling_height_mean_chris_1000  \\\n",
       "5000000.0                           0.0                             0.0   \n",
       "5000001.0                           0.0                             0.0   \n",
       "5000002.0                           0.0                             0.0   \n",
       "5000003.0                           0.0                             0.0   \n",
       "5000004.0                           0.0                             0.0   \n",
       "\n",
       "           rolling_width_mean_chris_1000  rolling_height_mean_chris_2500  \\\n",
       "5000000.0                            0.0                             0.0   \n",
       "5000001.0                            0.0                             0.0   \n",
       "5000002.0                            0.0                             0.0   \n",
       "5000003.0                            0.0                             0.0   \n",
       "5000004.0                            0.0                             0.0   \n",
       "\n",
       "           rolling_width_mean_chris_2500  ...  signal_shift_wave_+1_msignal  \\\n",
       "5000000.0                            0.0  ...                    0.00000000   \n",
       "5000001.0                            0.0  ...                    0.14182432   \n",
       "5000002.0                            0.0  ...                    0.15246851   \n",
       "5000003.0                            0.0  ...                   -0.27248720   \n",
       "5000004.0                            0.0  ...                   -0.09194352   \n",
       "\n",
       "           signal_shift_wave_-1_msignal  signal_shift_+1_FFT_msignal  \\\n",
       "5000000.0                   -0.05779149                   0.00000000   \n",
       "5000001.0                    0.14185280                   0.16037293   \n",
       "5000002.0                    0.15249648                   0.17100138   \n",
       "5000003.0                   -0.27246051                  -0.25397018   \n",
       "5000004.0                   -0.09191785                  -0.07344172   \n",
       "\n",
       "           signal_shift_-1_FFT_msignal  signal_shift+2  signal_shift-2  \\\n",
       "5000000.0                  -0.03925862         0.00000        -2.86009   \n",
       "5000001.0                   0.16036982         0.00000        -2.43512   \n",
       "5000002.0                   0.17099828        -2.64983        -2.61565   \n",
       "5000003.0                  -0.25397327        -2.84946        -2.56608   \n",
       "5000004.0                  -0.07344481        -2.86009        -2.73801   \n",
       "\n",
       "           signal_shift+2_wave_-1  signal_shift-2_wave_-1  signal_shift+2_FFT  \\\n",
       "5000000.0              0.00000000             -2.70760720          0.00000000   \n",
       "5000001.0              0.00000000             -2.70759352          0.00000000   \n",
       "5000002.0             -2.70763568             -2.70758051         -2.68908707   \n",
       "5000003.0             -2.70762149             -2.70756785         -2.68908862   \n",
       "5000004.0             -2.70760720             -2.70755576         -2.68909018   \n",
       "\n",
       "           signal_shift-2_FFT  \n",
       "5000000.0         -2.68909018  \n",
       "5000001.0         -2.68909172  \n",
       "5000002.0         -2.68909327  \n",
       "5000003.0         -2.68909481  \n",
       "5000004.0         -2.68909635  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv('/Users/siero5335/channel/train_mod.csv')\n",
    "#test.to_csv('/Users/siero5335/channel/test_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [c for c in train.columns if c not in ['time', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]\n",
    "\n",
    "train = train[col]\n",
    "test = test[col]\n",
    "\n",
    "n_fold = 5\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sun Mar  8 17:44:25 2020\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.057285\tvalid_1's l1: 0.0576737\n",
      "[200]\ttraining's l1: 0.0495938\tvalid_1's l1: 0.0503906\n"
     ]
    }
   ],
   "source": [
    "oof = np.zeros(len(train))\n",
    "prediction = np.zeros(len(test))\n",
    "scores = []\n",
    "\n",
    "params = {'learning_rate': 0.05, 'max_depth': -1, 'num_leaves':2**7+1, 'metric': 'mae', 'random_state': 7, 'n_jobs':-1} \n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(train, train_y)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = train.iloc[train_index], train.iloc[valid_index]\n",
    "    y_train, y_valid = train_y.iloc[train_index], train_y.iloc[valid_index]\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**params, n_estimators = 5000)\n",
    "    model.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='mae',\n",
    "            verbose=100, early_stopping_rounds=100)\n",
    "\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    y_pred = model.predict(test, num_iteration=model.best_iteration_)\n",
    "\n",
    "    oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "    scores.append(mean_absolute_error(y_valid, y_pred_valid))\n",
    "\n",
    "    prediction += y_pred\n",
    "\n",
    "prediction /= n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    \"\"\"\n",
    "    An optimizer for rounding thresholds\n",
    "    to maximize F1 (Macro) score\n",
    "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _f1_loss(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        Get loss according to\n",
    "        using current coefficients\n",
    "        \n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "        return -f1_score(y, X_p, average = 'macro')\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Optimize rounding thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        loss_partial = partial(self._f1_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \"\"\"\n",
    "        Make predictions with specified thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        \"\"\"\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "\n",
    "    def coefficients(self):\n",
    "        \"\"\"\n",
    "        Return the optimized coefficients\n",
    "        \"\"\"\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optR = OptimizedRounder()\n",
    "optR.fit(oof.reshape(-1,), train_y)\n",
    "coefficients = optR.coefficients()\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_preds = optR.predict(oof.reshape(-1,), coefficients)\n",
    "f1_score(train_y, opt_preds, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[prediction <= coefficients[0]] = 0\n",
    "prediction[np.where(np.logical_and(prediction > coefficients[0], prediction <= coefficients[1]))] = 1\n",
    "prediction[np.where(np.logical_and(prediction > coefficients[1], prediction <= coefficients[2]))] = 2\n",
    "prediction[np.where(np.logical_and(prediction > coefficients[2], prediction <= coefficients[3]))] = 3\n",
    "prediction[np.where(np.logical_and(prediction > coefficients[3], prediction <= coefficients[4]))] = 4\n",
    "prediction[np.where(np.logical_and(prediction > coefficients[4], prediction <= coefficients[5]))] = 5\n",
    "prediction[np.where(np.logical_and(prediction > coefficients[5], prediction <= coefficients[6]))] = 6\n",
    "prediction[np.where(np.logical_and(prediction > coefficients[6], prediction <= coefficients[7]))] = 7\n",
    "prediction[np.where(np.logical_and(prediction > coefficients[7], prediction <= coefficients[8]))] = 8\n",
    "prediction[np.where(np.logical_and(prediction > coefficients[8], prediction <= coefficients[9]))] = 9\n",
    "prediction[prediction > coefficients[9]] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['open_channels'] = prediction.astype(np.int)\n",
    "sample_submission.to_csv('submission_reg20200307_mae_5cv_f.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model,importance_type='split', max_num_features=100, figsize=(20, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
